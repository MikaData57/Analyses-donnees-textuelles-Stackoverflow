{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align:center;\"><img src=\"http://www.mf-data-science.fr/images/projects/intro.jpg\" style='width:100%; margin-left: auto; margin-right: auto; display: block;' /></div>","metadata":{}},{"cell_type":"markdown","source":"# <font color=\"#641E16\">Contexte</font>\nNous allons ici développer un algorithme de Machine Learning destiné à assigner automatiquement plusieurs tags pertinents à une question posée sur le célébre site Stack overflow.     \nCe programme s'adresse principalement aux nouveaux utilisateurs, afin de leur suggérer quelques tags relatifs à la question qu'ils souhaitent poser.\n\n### Les données sources\nLes données ont été captées via l'outil d’export de données ***stackexchange explorer***, qui recense un grand nombre de données authentiques de la plateforme d’entraide.     \nElles portent sur la période 2009 / 2020 et **uniquement sur les posts \"de qualité\"** ayant au minimum 1 réponse, 5 commentaires, 20 vues et un score supérieur à 5.\n\n### Objectif de ce Notebook\nDans ce Notebook, nous allons traiter la partie **data cleaning et exploration des données**. Un second notebook traitera ensuite les approches supervisées et non supervisées pour traiter la création de Tags à partir des données textuelles.     \n\nTous les Notebooks du projet seront **versionnés dans Kaggle mais également dans un repo GitHub** disponible à l'adresse https://github.com/MikaData57/Analyses-donnees-textuelles-Stackoverflow","metadata":{}},{"cell_type":"markdown","source":"# <font color=\"#641E16\">Sommaire</font>\n1. [Importation et description des données](#section_1)","metadata":{}},{"cell_type":"code","source":"# Install package for PEP8 verification\n!pip install pycodestyle\n!pip install --index-url https://test.pypi.org/simple/ nbpep8","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:46:17.769293Z","iopub.execute_input":"2021-06-08T12:46:17.769649Z","iopub.status.idle":"2021-06-08T12:46:34.930718Z","shell.execute_reply.started":"2021-06-08T12:46:17.76962Z","shell.execute_reply":"2021-06-08T12:46:34.92947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Python libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import KBinsDiscretizer\n\n# Library for PEP8 standard\nfrom nbpep8.nbpep8 import pep8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-08T12:47:03.738264Z","iopub.execute_input":"2021-06-08T12:47:03.738665Z","iopub.status.idle":"2021-06-08T12:47:03.747571Z","shell.execute_reply.started":"2021-06-08T12:47:03.738627Z","shell.execute_reply":"2021-06-08T12:47:03.746543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#641E16\" id=\"section_1\">Importation et description des données</font>","metadata":{}},{"cell_type":"code","source":"# Define path to data\npath = '../input/stackoverflow-questions-filtered-2011-2021/'\n\n# Concat all CSV datasets in one Pandas DataFrame\ndf_columns = pd.read_csv(path+'StackOverflow_questions_2009.csv').columns\ndata = pd.DataFrame(columns=df_columns)\nfor f in os.listdir(path):\n    temp = pd.read_csv(path+f)\n    data = pd.concat([data, temp], axis=0)\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T12:58:48.021369Z","iopub.execute_input":"2021-06-08T12:58:48.021774Z","iopub.status.idle":"2021-06-08T12:58:51.063202Z","shell.execute_reply.started":"2021-06-08T12:58:48.021733Z","shell.execute_reply":"2021-06-08T12:58:51.062201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print full dataset infos\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:00:28.839924Z","iopub.execute_input":"2021-06-08T13:00:28.840508Z","iopub.status.idle":"2021-06-08T13:00:29.104362Z","shell.execute_reply.started":"2021-06-08T13:00:28.840474Z","shell.execute_reply":"2021-06-08T13:00:29.102945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Describe data\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:35:17.972398Z","iopub.execute_input":"2021-06-08T13:35:17.972881Z","iopub.status.idle":"2021-06-08T13:35:18.765972Z","shell.execute_reply.started":"2021-06-08T13:35:17.972849Z","shell.execute_reply":"2021-06-08T13:35:18.764792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le jeu de données ne compte pas de valeurs nulles. Nous allons à présent vérifier la **longeur des différents titres** de la base :","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 12))\nax = sns.countplot(x=data.Title.str.len())\nstart, end = ax.get_xlim()\nax.xaxis.set_ticks(np.arange(0, end, 5))\nplt.axvline(data.Title.str.len().median() - data.Title.str.len().min(),\n            color=\"r\", linestyle='--',\n            label=\"Title Lenght median : \"+str(data.Title.str.len().median()))\nax.set_xlabel(\"Lenght of title\")\nplt.title(\"Title lenght of Stackoverflow questions\",\n          fontsize=18, color=\"#641E16\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T14:31:55.261252Z","iopub.execute_input":"2021-06-08T14:31:55.261638Z","iopub.status.idle":"2021-06-08T14:31:56.424934Z","shell.execute_reply.started":"2021-06-08T14:31:55.261594Z","shell.execute_reply":"2021-06-08T14:31:56.423897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous allons également ploter la répartition des **longueurs de la variable** `Body` *(les corps de texte des questions)*. L'étendue étant très importante, nous allons dans un premier temps **discrétiser ces longueur** pour ne pas surcharger les temps de calculs de projection graphique :","metadata":{}},{"cell_type":"code","source":"# Discretizer for Body characters lenght\nX = pd.DataFrame(data.Body.str.len())\n\n# Sklearn discretizer with 200 bins\ndiscretizer = KBinsDiscretizer(n_bins=200,\n                               encode='ordinal',\n                               strategy='uniform')\nbody_lenght = discretizer.fit_transform(X)\nbody_lenght = discretizer.inverse_transform(body_lenght)\nbody_lenght = pd.Series(body_lenght.reshape(-1))","metadata":{"execution":{"iopub.status.busy":"2021-06-08T15:18:29.211841Z","iopub.execute_input":"2021-06-08T15:18:29.212251Z","iopub.status.idle":"2021-06-08T15:18:29.549453Z","shell.execute_reply.started":"2021-06-08T15:18:29.212215Z","shell.execute_reply":"2021-06-08T15:18:29.548313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 12))\nax = sns.countplot(x=body_lenght)\nstart, end = ax.get_xlim()\nax.xaxis.set_ticks(np.arange(0, end, 25))\nax.set_xlabel(\"Lenght of Body (after discretization)\")\nplt.title(\"Body lenght of Stackoverflow questions\",\n          fontsize=18, color=\"#641E16\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T15:18:45.997612Z","iopub.execute_input":"2021-06-08T15:18:45.998177Z","iopub.status.idle":"2021-06-08T15:18:47.108775Z","shell.execute_reply.started":"2021-06-08T15:18:45.998142Z","shell.execute_reply":"2021-06-08T15:18:47.107942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque que la majeur partie des questions compte moins de 4000 caractères *(balises HTML compris)* mais certains posts dépassent les 31 000 caractères. ","metadata":{}},{"cell_type":"code","source":"pep8(_ih)","metadata":{},"execution_count":null,"outputs":[]}]}