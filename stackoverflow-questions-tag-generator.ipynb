{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align:center;\"><img src=\"http://www.mf-data-science.fr/images/projects/intro.jpg\" style='width:100%; margin-left: auto; margin-right: auto; display: block;' /></div>","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color: #641E16\">Contexte</span>\nNous allons ici développer un algorithme de Machine Learning destiné à assigner automatiquement plusieurs tags pertinents à une question posée sur le célébre site Stack overflow.     \nCe programme s'adresse principalement aux nouveaux utilisateurs, afin de leur suggérer quelques tags relatifs à la question qu'ils souhaitent poser.\n\n### Les données sources\nLes données ont été cleanées dans le Notebook Kaggle [Stackoverflow questions - data cleaning](https://www.kaggle.com/michaelfumery/stackoverflow-questions-data-cleaning). Dans ce nettoyage ont par exemple été appliquées les techniques de stop words, suppression de la ponctuation et des liens, tokenisation, lemmatisation ...\n\n### Objectif de ce Notebook\nDans ce Notebook, nous allons traiter la partie **modélisation des données textuelles avec des modèles supervisés et non supervisés**.     \n\nTous les Notebooks du projet seront **versionnés dans Kaggle mais également dans un repo GitHub** disponible à l'adresse https://github.com/MikaData57/Analyses-donnees-textuelles-Stackoverflow","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\">Sommaire</span>\n1. [Preprocessing : Bag of Words / Tf-Idf](#section_1)\n2. [Modèles non supervisés](#section_2)     \n    2.1. [Modèle LDA](#section_2_1)     \n    2.2. [Modèle NMF](#section_2_2)     ","metadata":{}},{"cell_type":"code","source":"# Install package for PEP8 verification\n!pip install pycodestyle\n!pip install --index-url https://test.pypi.org/simple/ nbpep8","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:51:37.061749Z","iopub.execute_input":"2021-06-23T09:51:37.063147Z","iopub.status.idle":"2021-06-23T09:51:50.82499Z","shell.execute_reply.started":"2021-06-23T09:51:37.063082Z","shell.execute_reply":"2021-06-23T09:51:50.823408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Python libraries\nimport os\nimport warnings\nimport time\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\nimport re\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import LatentDirichletAllocation, NMF\nfrom sklearn.model_selection import GridSearchCV\nimport gensim\nfrom scipy.sparse import hstack\nimport pyLDAvis\nimport pyLDAvis.sklearn\nimport pyLDAvis.gensim_models as gensimvis\n\n# Library for PEP8 standard\nfrom nbpep8.nbpep8 import pep8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-23T09:51:50.828649Z","iopub.execute_input":"2021-06-23T09:51:50.829022Z","iopub.status.idle":"2021-06-23T09:51:50.840388Z","shell.execute_reply.started":"2021-06-23T09:51:50.828975Z","shell.execute_reply":"2021-06-23T09:51:50.839096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore', category=DeprecationWarning)\nplt.style.use('seaborn-whitegrid')\nsns.set_style(\"whitegrid\")","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:51:50.843248Z","iopub.execute_input":"2021-06-23T09:51:50.843706Z","iopub.status.idle":"2021-06-23T09:51:50.866172Z","shell.execute_reply.started":"2021-06-23T09:51:50.84364Z","shell.execute_reply":"2021-06-23T09:51:50.864795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define path to data\npath = '../input/stackoverflow-questions-filtered-2011-2021/'\ndata = pd.read_csv(path+\"StackOverflow_questions_2009_2020_cleaned.csv\",\n                   sep=\";\", index_col=0,\n                   converters={\"Title\": literal_eval,\n                               \"Body\": literal_eval,\n                               \"Tags\": literal_eval})\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:51:50.868503Z","iopub.execute_input":"2021-06-23T09:51:50.868931Z","iopub.status.idle":"2021-06-23T09:51:57.795004Z","shell.execute_reply.started":"2021-06-23T09:51:50.868897Z","shell.execute_reply":"2021-06-23T09:51:57.793865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:51:57.796541Z","iopub.execute_input":"2021-06-23T09:51:57.796929Z","iopub.status.idle":"2021-06-23T09:51:57.804168Z","shell.execute_reply.started":"2021-06-23T09:51:57.796894Z","shell.execute_reply":"2021-06-23T09:51:57.803139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous allons également créer une variable `Full_doc` qui accueillera le document complet de chaque item (Title et Body) :","metadata":{}},{"cell_type":"code","source":"data[\"Full_doc\"] = data[\"Title\"] + data[\"Body\"]\ndata[\"Full_doc\"].head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:51:57.807539Z","iopub.execute_input":"2021-06-23T09:51:57.807878Z","iopub.status.idle":"2021-06-23T09:51:59.118736Z","shell.execute_reply.started":"2021-06-23T09:51:57.80784Z","shell.execute_reply":"2021-06-23T09:51:59.117323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\" id=\"section_1\">Preprocessing : Bag of Words / Tf-Idf</span>\n\nPour alimenter les modèles de machine learning, nous avons besoin de traiter des données numériques. Le modèle **Bag of Words** apprend un vocabulaire à partir de tous les documents, puis modélise chaque document en comptant le nombre de fois où chaque mot apparaît, convertissant donc les données textuelles en données numériques.\n\nNos données ayant déjà été cleanées et tokenisées dans le Notebook [stackoverflow-questions-data-cleaning](https://www.kaggle.com/michaelfumery/stackoverflow-questions-data-cleaning), nous allons initialiser l'algorithme du `CountVectorizer` sur les variables `Title` et `Body` *(X1 et X2)* sans preprocessing. Enfin, nous allons utiliser le module `TfidfVectorizer` de la librairie Scikit-Learn pour combiner le `CountVectorizer` et `TfidfTransformer`. Cela aura pour effet de pondérer la fréquence d'apparition des par un indicateur de similarité *(si ce mot est commun ou rare dans tous les documents)*. Dans cette partie, nous allons **éliminer les mots qui apparaissent dans plus de 60% des documents** (`max_df = 0.6`).\n\nla métrique tf-idf ***(Term-Frequency - Inverse Document Frequency)*** utilise comme indicateur de similarité l'inverse document frequency qui est l'inverse de la proportion de document qui contient le terme, à l'échelle logarithmique.\n\nPour préparer nos targets *(pour les modèles supervisés)*, nous allons utiliser `MultiLabelBinarizer` de Scikit-Learn puisque nos `Tags` sont multiples.","metadata":{}},{"cell_type":"code","source":"# Initialize the \"CountVectorizer\" object for Title, Body and Full_doc\ntitle_vectorizer = TfidfVectorizer(analyzer=\"word\",\n                                   max_df=.6,\n                                   min_df=0.005,\n                                   tokenizer=None,\n                                   preprocessor=' '.join,\n                                   stop_words=None,\n                                   lowercase=False)\n\nbody_vectorizer = TfidfVectorizer(analyzer=\"word\",\n                                  max_df=.6,\n                                  min_df=0.005,\n                                  tokenizer=None,\n                                  preprocessor=' '.join,\n                                  stop_words=None,\n                                  lowercase=False)\n\nfull_vectorizer = TfidfVectorizer(analyzer=\"word\",\n                                  max_df=.6,\n                                  min_df=0.005,\n                                  tokenizer=None,\n                                  preprocessor=' '.join,\n                                  stop_words=None,\n                                  lowercase=False)\n\nXt_tfidf = title_vectorizer.fit_transform(data[\"Title\"])\nXb_tfidf = body_vectorizer.fit_transform(data[\"Body\"])\nX_tfidf = full_vectorizer.fit_transform(data[\"Full_doc\"])\n\nprint(\"Shape of X for Title: {}\".format(Xt_tfidf.shape))\nprint(\"Shape of X for Body: {}\".format(Xb_tfidf.shape))\nprint(\"Shape of X for Full_doc: {}\".format(X_tfidf.shape))\n\n# Multilabel binarizer for targets\nmultilabel_binarizer = MultiLabelBinarizer() \ny = multilabel_binarizer.fit_transform(data[\"Tags\"])\nprint(\"Shape of y: {}\".format(y.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:51:59.120006Z","iopub.execute_input":"2021-06-23T09:51:59.120357Z","iopub.status.idle":"2021-06-23T09:52:06.927935Z","shell.execute_reply.started":"2021-06-23T09:51:59.120325Z","shell.execute_reply":"2021-06-23T09:52:06.926885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous avons à présent une matrice de 30846 lignes et 4306 colonnes qui sera interprétable par nos modèles de Machine Learning. Comme les matrices sont relativment importantes, nous allons **vérifier le nombre de cellules qui ne sont pas à 0** :","metadata":{}},{"cell_type":"code","source":"title_dense = Xt_tfidf.todense()\nbody_dense = Xb_tfidf.todense()\nfull_dense = X_tfidf.todense()\nprint(\"Title sparsicity: {:.3f} %\"\\\n      .format(((title_dense > 0).sum()/title_dense.size)*100))\nprint(\"Body sparsicity: {:.3f} %\"\\\n      .format(((body_dense > 0).sum()/body_dense.size)*100))\nprint(\"Full_doc sparsicity: {:.3f} %\"\\\n      .format(((full_dense > 0).sum()/full_dense.size)*100))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:52:06.931387Z","iopub.execute_input":"2021-06-23T09:52:06.931881Z","iopub.status.idle":"2021-06-23T09:52:09.427529Z","shell.execute_reply.started":"2021-06-23T09:52:06.931835Z","shell.execute_reply":"2021-06-23T09:52:09.426349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous constatons que cette mesure est meilleure pour la varaible englobant Title et Body *(Full_doc)*.","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\" id=\"section_2\">Modèles non supervisés</span>\n\n## <span id=\"section_2_1\">Modèle LDA</span>\nLDA, ou **Latent Derelicht Analysis** est un modèle probabiliste qui, pour obtenir des affectations de cluster, utilise deux valeurs de probabilité : $P(word | topics)$ et $P(topics | documents)$. Ces valeurs sont calculées sur la base d'une attribution aléatoire initiale, puis le calcul est répété pour chaque mot dans chaque document, pour décider de leur attribution de sujet. Dans cette méthode itérative, ces probabilités sont calculées plusieurs fois, jusqu'à la convergence de l'algorithme.\n\nNous allons entrainer 3 modèles séparement pour le `Title`, le `Body` et `Full_doc` :","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start LDA fitting on Title ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the LDA on Title\ntitle_lda = LatentDirichletAllocation(n_components=20,\n                                      random_state=8,\n                                      n_jobs=-1)\n\n# Fit LDA on Title\ntitle_lda.fit(Xt_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:52:09.429581Z","iopub.execute_input":"2021-06-23T09:52:09.430083Z","iopub.status.idle":"2021-06-23T09:52:50.710572Z","shell.execute_reply.started":"2021-06-23T09:52:09.430033Z","shell.execute_reply":"2021-06-23T09:52:50.709498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:#641E16;\">Visualisation des résultats de LDA Sklearn sur Title</span>","metadata":{}},{"cell_type":"code","source":"pyLDAvis.enable_notebook()\npyLDAvis.sklearn.prepare(title_lda, \n                         Xt_tfidf, \n                         title_vectorizer)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:52:50.711963Z","iopub.execute_input":"2021-06-23T09:52:50.712259Z","iopub.status.idle":"2021-06-23T09:52:54.200864Z","shell.execute_reply.started":"2021-06-23T09:52:50.712231Z","shell.execute_reply":"2021-06-23T09:52:54.1998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start LDA fitting on Body ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the LDA\nbody_lda = LatentDirichletAllocation(n_components=20,\n                                     random_state=8,\n                                     n_jobs=-1)\n\n# Fit LDA on Body\nbody_lda.fit(Xb_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:52:54.202011Z","iopub.execute_input":"2021-06-23T09:52:54.202285Z","iopub.status.idle":"2021-06-23T09:55:32.406536Z","shell.execute_reply.started":"2021-06-23T09:52:54.202259Z","shell.execute_reply":"2021-06-23T09:55:32.405328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:#641E16;\">Visualisation des résultats de LDA Sklearn sur Body</span>","metadata":{}},{"cell_type":"code","source":"pyLDAvis.sklearn.prepare(body_lda, \n                         Xb_tfidf, \n                         body_vectorizer)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:55:32.408931Z","iopub.execute_input":"2021-06-23T09:55:32.40951Z","iopub.status.idle":"2021-06-23T09:55:46.041124Z","shell.execute_reply.started":"2021-06-23T09:55:32.409449Z","shell.execute_reply":"2021-06-23T09:55:46.039823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start LDA fitting on Full_doc ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the LDA\nfull_lda = LatentDirichletAllocation(n_components=20,\n                                     random_state=8,\n                                     n_jobs=-1)\n\n# Fit LDA on Full_doc\nfull_lda.fit(X_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:55:46.042811Z","iopub.execute_input":"2021-06-23T09:55:46.043258Z","iopub.status.idle":"2021-06-23T09:58:25.752957Z","shell.execute_reply.started":"2021-06-23T09:55:46.043215Z","shell.execute_reply":"2021-06-23T09:58:25.75171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:#641E16;\">Visualisation des résultats de LDA Sklearn sur Full_doc</span>","metadata":{}},{"cell_type":"code","source":"pyLDAvis.sklearn.prepare(full_lda, \n                         X_tfidf, \n                         full_vectorizer)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:58:25.754562Z","iopub.execute_input":"2021-06-23T09:58:25.754999Z","iopub.status.idle":"2021-06-23T09:58:39.246434Z","shell.execute_reply.started":"2021-06-23T09:58:25.754954Z","shell.execute_reply":"2021-06-23T09:58:39.24564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Que ce soit avec la variable `Title` ou avec la variable `Body`, il semble très **difficile de \"nommer\" les topics créés car les mots qui les composent sont très variés et sans réél fil conducteur**. LDA sur le document complet `Full_doc`, englobant les tokens de Title et Body semble donner des résultats plus cohérents.\n\nCependant, dans ces algoritmes LDA, nous avons fixé arbitrairement le paramètre `n_components` qui représente le nombre de topics à créer. Afin de sélectionner le meilleur nombre de topics à créer, nous allons utiliser une `GridSearch` avec Cross-validation et testerons 2 métriques :\n- Log likelihood : Densité de vraisemblance \n- Perplexity : $(\\exp(-1 \\times \\text{log-likelihood})$\n\nRegardons déjà ces métriques obtenues sur nos premiers modèles :","metadata":{}},{"cell_type":"code","source":"# Log Likelihood\nprint(\"-\"*50)\nprint(\"Log Likelihood\")\nprint(\"-\" * 50)\nprint(\"Log Likelihood on Title Model : {}\".format(title_lda.score(Xt_tfidf)))\nprint(\"Log Likelihood on Body Model : {}\".format(body_lda.score(Xb_tfidf)))\nprint(\"Log Likelihood on Full_doc Model : {}\".format(full_lda.score(X_tfidf)))\n\n# Perplexity\nprint(\"-\"*50)\nprint(\"Perplexity\")\nprint(\"-\" * 50)\nprint(\"Perplexity on Title Model : {}\".format(title_lda.perplexity(Xt_tfidf)))\nprint(\"Perplexity on Body Model : {}\".format(body_lda.perplexity(Xb_tfidf)))\nprint(\"Perplexity on Full_doc Model : {}\".format(full_lda.perplexity(X_tfidf)))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T09:58:39.247626Z","iopub.execute_input":"2021-06-23T09:58:39.248158Z","iopub.status.idle":"2021-06-23T10:00:03.537803Z","shell.execute_reply.started":"2021-06-23T09:58:39.248125Z","shell.execute_reply":"2021-06-23T10:00:03.536712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Amélioration des paramètres :\nUn modèle avec une log-likelihood plus élevée et une perplexité plus faible est considéré comme bon. Ici, on remarque que **notre modèle ne semble pas très performant**.\nAppliquons maintenant une itération sur le nombre de topics de notre LDA avec la variable `Full_doc` :","metadata":{}},{"cell_type":"code","source":"kmin, kmax = 1, 100\ntopic_models = []\n\nfor k in np.arange(kmin, kmax, 10):\n    print(\"-\"*50)\n    print(\"Applying LDA for k = {}\".format(k))\n    print(\"-\"*50)\n    # Run LDA\n    model = LatentDirichletAllocation(n_components=k,\n                                      random_state=8,\n                                      n_jobs=-1)\n    W = model.fit_transform(X_tfidf)\n    H = model.components_\n    loglikelihood = model.score(X_tfidf)\n    perplexity = model.perplexity(X_tfidf)\n    topic_models.append((k, W, H, loglikelihood, perplexity))\n    print(\"Indicative Loglikelihood = {:.2f}\".format(loglikelihood))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T10:00:03.539378Z","iopub.execute_input":"2021-06-23T10:00:03.540035Z","iopub.status.idle":"2021-06-23T10:31:02.908845Z","shell.execute_reply.started":"2021-06-23T10:00:03.53999Z","shell.execute_reply":"2021-06-23T10:31:02.907761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_models = pd.DataFrame(topic_models,\n                            columns=[\"N_components\", \"X_Transform\",\n                                     \"Model_component\",\n                                     \"Loglikelihood\", \"Perplexity\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Affichons les scores des divers modèle :","metadata":{}},{"cell_type":"code","source":"# Show graph\nfig, ax1 = plt.subplots(figsize=(12, 8))\nx = topic_models['N_components']\ny1 = topic_models['Loglikelihood']\nax1.plot(x, y1, label='Loglikelihood score')\nax1.axvline(x=1, color='r', alpha=.7,\n            linestyle='dashdot', label='Best param')\nax1.set_xlabel(\"Number of topics\")\nax1.set_ylabel(\"Loglikelihood Score\")\n\nax2 = ax1.twinx()\ny2 = topic_models['Perplexity']\nax2.plot(x, y2, label='Perplexity score',\n         color='g', alpha=.5,\n         linestyle='--',)\nax2.set_ylabel(\"Perplexity score\")\n\nplt.title(\"Choosing Optimal LDA Model\\n\",\n          color=\"#641E16\", fontsize=18)\nlegend = fig.legend(loc=1, bbox_to_anchor=(.92, .9))\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T12:53:04.11993Z","iopub.execute_input":"2021-06-23T12:53:04.120342Z","iopub.status.idle":"2021-06-23T12:53:04.762743Z","shell.execute_reply.started":"2021-06-23T12:53:04.12031Z","shell.execute_reply":"2021-06-23T12:53:04.761511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque ici que la modélisation non supervisée avec LDA n'est pas adaptée. En effet, le meilleur nombre de topics se situerait à 1, ce qui signifie que **l'algorithme ne parvient pas a établir de groupes bien distincts**.\n\nNous allons donc tester une seconde modélisation non supervisée.\n\n## <span id=\"section_2_2\">Modèle NMF</span>\n<details>\n  <summary style=\"color:blue;\">Explication du modèle</summary>\n  \n  ## NMF\n  La factorisation matricielle non négative *(**N**on-negative **M**atrix **F**actorization)* est un modèle linéaire-algéabrique, qui factorise des vecteurs de grande dimension dans une représentation de faible dimension. Similaire à l'analyse en composantes principales *(PCA)*, NMF profite du fait que **les vecteurs sont non négatifs**. En les factorisant dans la forme de dimension inférieure, NMF force les coefficients à être également non négatifs.<br/><br/>\n    Prenons une matrice d'origine $A$, nous pouvons obtenir deux matrices $W$ et $H$, telles que $A = WH$. NMF a une propriété de clustering, telle que $W$ et $H$ représentent les informations suivantes sur $A$ :\n    <ul><li>$A$ (Matrice Document-word) : Matrice qui contient \"quels mots apparaissent dans quels documents\".</li>\n    <li>$W$ (Vecteurs de base) : Topics découverts à partir des documents.</li>\n    <li>$H$ (Matrice de coefficients) : les poids pour les topics dans chaque document.</li></ul><br/>\n    Nous calculons $W$ et $H$ en optimisant sur une **fonction objectif**, en mettant à jour à la fois $W$ et $H$ de manière itérative jusqu'à convergence.</br></br>\n    $$\\large \\frac{1}{2} ||A - WH||^2_F = \\sum_{i=1}^{n} \\sum_{j=1}^{m} (A_{ij} - (WH)_{ij})^2$$</br>\n    Dans cette fonction objectif, nous mesurons l'erreur de reconstruction entre A et le produit de ses facteurs W et H, en fonction de la distance euclidienne. Les valeurs mises à jour sont calculées dans des opérations parallèles, et en utilisant les nouveaux W et H, nous recalculons l'erreur de reconstruction, en répétant ce processus jusqu'à la convergence.\n</details>","metadata":{}},{"cell_type":"markdown","source":"Le modèle **NMF ne peut malheureusement pas être scoré** dans une GridSearch. Nous allons donc nous baser sur les résultats de la GridSearch LDA pour déterminer un nombre correct de composants. Ici, nous prendrons **10 topics** pour avoir un bon compromis \"temps d'entrainement\" / précision.","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start NMF fitting on Title ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\ntitle_nmf = NMF(n_components=10,\n                init='nndsvd',\n                random_state=8)\n\n# Fit NMF on Title vectorized\ntitle_nmf.fit(Xt_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T12:53:42.031993Z","iopub.execute_input":"2021-06-23T12:53:42.03243Z","iopub.status.idle":"2021-06-23T12:53:44.013181Z","shell.execute_reply.started":"2021-06-23T12:53:42.032396Z","shell.execute_reply":"2021-06-23T12:53:44.010329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'entrainement est plus rapide que pour LDA. Visualisons à présent les résulats en plotant **les 20 meilleurs mots de chaque topic**.","metadata":{}},{"cell_type":"code","source":"def plot_top_words(model, feature_names, n_top_words, title):\n    \"\"\"Function for displaying the plots of the \n    best x words representative of the categories of NMF.\n\n    Parameters\n    ----------------------------------------\n    model : NMF model\n        Fitted model of NMF to plot\n    feature_names : array\n        Categories result of the vectorizer (TFIDF ...)\n    n_top_words : int\n        Number of words for each topic.\n    title : string\n        Title of the plot.\n    ----------------------------------------\n    \"\"\"\n    fig, axes = plt.subplots(2, 5, figsize=(30, 20), sharex=True)\n    axes = axes.flatten()\n    for topic_idx, topic in enumerate(model.components_):\n        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        weights = topic[top_features_ind]\n\n        ax = axes[topic_idx]\n        bartopic = ax.barh(top_features, weights, height=0.7)\n        bartopic[0].set_color('#f48023')\n        ax.set_title(f'Topic {topic_idx +1}',\n                     fontdict={'fontsize': 30})\n        ax.invert_yaxis()\n        ax.tick_params(axis='both', which='major', labelsize=20)\n        for i in 'top right left'.split():\n            ax.spines[i].set_visible(False)\n        fig.suptitle(title, fontsize=36, color=\"#641E16\")\n\n    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T12:53:51.860823Z","iopub.execute_input":"2021-06-23T12:53:51.861182Z","iopub.status.idle":"2021-06-23T12:53:51.871125Z","shell.execute_reply.started":"2021-06-23T12:53:51.861152Z","shell.execute_reply":"2021-06-23T12:53:51.870298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_feature_names = title_vectorizer.get_feature_names()\nplot_top_words(title_nmf, tf_feature_names, 20, 'Topics in NMF model for Title feature')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T12:53:58.114173Z","iopub.execute_input":"2021-06-23T12:53:58.114702Z","iopub.status.idle":"2021-06-23T12:54:02.07701Z","shell.execute_reply.started":"2021-06-23T12:53:58.114657Z","shell.execute_reply":"2021-06-23T12:54:02.075732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**La modélisation avec NMF nous apporte des catégories plus lisibles que celles de l'algorithme LDA**. 1 mot est toujours plus représentaif de cette catégorie mais les regroupements sont globalement cohérents. Le topic 4 par exemple illustre bien les sujets liés à Python *(on y retrouve des mots comme Numpy, package par exemple)*. Le topic 6 traite les sujets liés à Android et le topic 1 semble traiter des sujets web.\n\nNous allons **tester cette modélisation sur la variable Body** cette fois :","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start NMF fitting on Body ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\nbody_nmf = NMF(n_components=10,\n               init='nndsvd',\n               random_state=8)\n\n# Fit NMF on Body vectorized\nbody_nmf.fit(Xb_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)\n\nbf_feature_names = body_vectorizer.get_feature_names()\nplot_top_words(body_nmf, bf_feature_names, 30, 'Topics in NMF model for Body feature')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T12:54:41.380109Z","iopub.execute_input":"2021-06-23T12:54:41.380792Z","iopub.status.idle":"2021-06-23T12:54:50.779348Z","shell.execute_reply.started":"2021-06-23T12:54:41.380737Z","shell.execute_reply":"2021-06-23T12:54:50.778301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Basé sur le corpus Body, le modèle fait sortir des thèmes différents, plus génériques. Le topic 2 par exemple traite des sujets liés à l'audio; le topic 3 des sujets liés à l'image et le topic 9 des sujets plus hardware ...\n**NMF est également beaucoup plus rapide que LDA**, ce qui est un atout pour en terme de puissance de calcul nécessaire.","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start NMF fitting on Full_doc ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\nfull_nmf = NMF(n_components=10,\n               init='nndsvd',\n               random_state=8)\n\n# Fit NMF on Body vectorized\nfull_nmf.fit(X_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)\n\nff_feature_names = full_vectorizer.get_feature_names()\nplot_top_words(full_nmf, ff_feature_names, 30, 'Topics in NMF model for Full_doc')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T12:57:43.720579Z","iopub.execute_input":"2021-06-23T12:57:43.721268Z","iopub.status.idle":"2021-06-23T12:57:57.523387Z","shell.execute_reply.started":"2021-06-23T12:57:43.721204Z","shell.execute_reply":"2021-06-23T12:57:57.522226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}