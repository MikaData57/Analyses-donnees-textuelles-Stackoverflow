{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"text-align:center;\"><img src=\"http://www.mf-data-science.fr/images/projects/intro.jpg\" style='width:100%; margin-left: auto; margin-right: auto; display: block;' /></div>","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color: #641E16\">Contexte</span>\nNous allons ici développer un algorithme de Machine Learning destiné à assigner automatiquement plusieurs tags pertinents à une question posée sur le célébre site Stack overflow.     \nCe programme s'adresse principalement aux nouveaux utilisateurs, afin de leur suggérer quelques tags relatifs à la question qu'ils souhaitent poser.\n\n### Les données sources\nLes données ont été cleanées dans le Notebook Kaggle [Stackoverflow questions - data cleaning](https://www.kaggle.com/michaelfumery/stackoverflow-questions-data-cleaning). Dans ce nettoyage ont par exemple été appliquées les techniques de stop words, suppression de la ponctuation et des liens, tokenisation, lemmatisation ...\n\n### Objectif de ce Notebook\nDans ce Notebook, nous allons traiter la partie **modélisation des données textuelles avec des modèles supervisés et non supervisés**.     \n\nTous les Notebooks du projet seront **versionnés dans Kaggle mais également dans un repo GitHub** disponible à l'adresse https://github.com/MikaData57/Analyses-donnees-textuelles-Stackoverflow","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\">Sommaire</span>\n1. [Preprocessing : Bag of Words / Tf-Idf](#section_1)\n2. [Modèles non supervisés](#section_2)     \n    2.1. [Modèle LDA](#section_2_1)     \n    2.2. [Modèle NMF](#section_2_2)     \n3. [Modèles supervisés](#section_3)     \n    3.1. [Régression logistique avec multi-labels](#section_3_1)","metadata":{}},{"cell_type":"code","source":"# Install package for PEP8 verification\n!pip install pycodestyle\n!pip install --index-url https://test.pypi.org/simple/ nbpep8","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:52:41.146778Z","iopub.execute_input":"2021-06-28T13:52:41.147074Z","iopub.status.idle":"2021-06-28T13:52:51.212739Z","shell.execute_reply.started":"2021-06-28T13:52:41.147049Z","shell.execute_reply":"2021-06-28T13:52:51.21175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Python libraries\nimport os\nimport warnings\nimport time\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import set_config\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import NMF\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.multioutput import ClassifierChain\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport sklearn.metrics as metrics\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel\nimport pyLDAvis\nimport pyLDAvis.sklearn\nimport pyLDAvis.gensim_models as gensimvis\n\n# Library for PEP8 standard\nfrom nbpep8.nbpep8 import pep8","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T13:52:51.214163Z","iopub.execute_input":"2021-06-28T13:52:51.214485Z","iopub.status.idle":"2021-06-28T13:52:51.222941Z","shell.execute_reply.started":"2021-06-28T13:52:51.214448Z","shell.execute_reply":"2021-06-28T13:52:51.22159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore', category=DeprecationWarning)\nplt.style.use('seaborn-whitegrid')\nsns.set_style(\"whitegrid\")\nset_config(display='diagram')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:52:51.224992Z","iopub.execute_input":"2021-06-28T13:52:51.225299Z","iopub.status.idle":"2021-06-28T13:52:51.244395Z","shell.execute_reply.started":"2021-06-28T13:52:51.225229Z","shell.execute_reply":"2021-06-28T13:52:51.243651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define path to data\npath = '../input/stackoverflow-questions-filtered-2011-2021/'\ndata = pd.read_csv(path+\"StackOverflow_questions_2009_2020_cleaned.csv\",\n                   sep=\";\", index_col=0,\n                   converters={\"Title\": literal_eval,\n                               \"Body\": literal_eval,\n                               \"Tags\": literal_eval})\ndata.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:52:51.245343Z","iopub.execute_input":"2021-06-28T13:52:51.24554Z","iopub.status.idle":"2021-06-28T13:52:55.832942Z","shell.execute_reply.started":"2021-06-28T13:52:51.245519Z","shell.execute_reply":"2021-06-28T13:52:55.831527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:52:55.834078Z","iopub.execute_input":"2021-06-28T13:52:55.834309Z","iopub.status.idle":"2021-06-28T13:52:55.839703Z","shell.execute_reply.started":"2021-06-28T13:52:55.834268Z","shell.execute_reply":"2021-06-28T13:52:55.838656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous allons également créer une variable `Full_doc` qui accueillera le document complet de chaque item (Title et Body) :","metadata":{}},{"cell_type":"code","source":"data[\"Full_doc\"] = data[\"Title\"] + data[\"Body\"]\ndata[\"Full_doc\"].head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:52:55.840985Z","iopub.execute_input":"2021-06-28T13:52:55.841329Z","iopub.status.idle":"2021-06-28T13:52:55.978646Z","shell.execute_reply.started":"2021-06-28T13:52:55.841271Z","shell.execute_reply":"2021-06-28T13:52:55.978093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\" id=\"section_1\">Preprocessing : Bag of Words / Tf-Idf</span>\n\nPour alimenter les modèles de machine learning, nous avons besoin de traiter des données numériques. Le modèle **Bag of Words** apprend un vocabulaire à partir de tous les documents, puis modélise chaque document en comptant le nombre de fois où chaque mot apparaît, convertissant donc les données textuelles en données numériques.\n\nNos données ayant déjà été cleanées et tokenisées dans le Notebook [stackoverflow-questions-data-cleaning](https://www.kaggle.com/michaelfumery/stackoverflow-questions-data-cleaning), nous allons initialiser l'algorithme du `CountVectorizer` sur les variables `Title` et `Body` *(X1 et X2)* sans preprocessing. Enfin, nous allons utiliser le module `TfidfVectorizer` de la librairie Scikit-Learn pour combiner le `CountVectorizer` et `TfidfTransformer`. Cela aura pour effet de pondérer la fréquence d'apparition des mots par un indicateur de similarité *(si ce mot est commun ou rare dans tous les documents)*. Dans cette partie, nous allons **éliminer les mots qui apparaissent dans plus de 60% des documents** (`max_df = 0.6`).\n\nla métrique tf-idf ***(Term-Frequency - Inverse Document Frequency)*** utilise comme indicateur de similarité l'inverse document frequency qui est l'inverse de la proportion de document qui contient le terme, à l'échelle logarithmique.\n\nPour préparer nos targets *(pour les modèles supervisés)*, nous allons utiliser `MultiLabelBinarizer` de Scikit-Learn puisque nos `Tags` sont multiples.","metadata":{}},{"cell_type":"code","source":"# Create train and test split (30%)\nX = data[[\"Title\", \"Body\", \"Full_doc\"]]\ny = data[\"Tags\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n\n# Initialize the \"CountVectorizer\" object for Title, Body and Full_doc\ntitle_vectorizer = TfidfVectorizer(analyzer=\"word\",\n                                   max_df=.6,\n                                   min_df=0.005,\n                                   tokenizer=None,\n                                   preprocessor=' '.join,\n                                   stop_words=None,\n                                   lowercase=False)\n\nbody_vectorizer = TfidfVectorizer(analyzer=\"word\",\n                                  max_df=.6,\n                                  min_df=0.005,\n                                  tokenizer=None,\n                                  preprocessor=' '.join,\n                                  stop_words=None,\n                                  lowercase=False)\n\nfull_vectorizer = TfidfVectorizer(analyzer=\"word\",\n                                  max_df=.6,\n                                  min_df=0.005,\n                                  tokenizer=None,\n                                  preprocessor=' '.join,\n                                  stop_words=None,\n                                  lowercase=False)\n\nXt_tfidf = title_vectorizer.fit_transform(X_train[\"Title\"])\nXb_tfidf = body_vectorizer.fit_transform(X_train[\"Body\"])\nX_tfidf = full_vectorizer.fit_transform(X_train[\"Full_doc\"])\n\nprint(\"Shape of X for Title: {}\".format(Xt_tfidf.shape))\nprint(\"Shape of X for Body: {}\".format(Xb_tfidf.shape))\nprint(\"Shape of X for Full_doc: {}\".format(X_tfidf.shape))\n\n# Multilabel binarizer for targets\nmultilabel_binarizer = MultiLabelBinarizer()\nmultilabel_binarizer.fit(y_train)\ny_binarized = multilabel_binarizer.transform(y_train)\ny_test_binarized = multilabel_binarizer.transform(y_test)\nprint(\"Shape of y: {}\".format(y_binarized.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:52:55.979574Z","iopub.execute_input":"2021-06-28T13:52:55.979787Z","iopub.status.idle":"2021-06-28T13:53:01.721613Z","shell.execute_reply.started":"2021-06-28T13:52:55.979759Z","shell.execute_reply":"2021-06-28T13:53:01.720509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comme les matrices sont relativment importantes, nous allons **vérifier le nombre de cellules qui ne sont pas à 0** :","metadata":{}},{"cell_type":"code","source":"title_dense = Xt_tfidf.todense()\nbody_dense = Xb_tfidf.todense()\nfull_dense = X_tfidf.todense()\nprint(\"Title sparsicity: {:.3f} %\"\\\n      .format(((title_dense > 0).sum()/title_dense.size)*100))\nprint(\"Body sparsicity: {:.3f} %\"\\\n      .format(((body_dense > 0).sum()/body_dense.size)*100))\nprint(\"Full_doc sparsicity: {:.3f} %\"\\\n      .format(((full_dense > 0).sum()/full_dense.size)*100))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:53:01.723763Z","iopub.execute_input":"2021-06-28T13:53:01.723988Z","iopub.status.idle":"2021-06-28T13:53:02.044558Z","shell.execute_reply.started":"2021-06-28T13:53:01.723963Z","shell.execute_reply":"2021-06-28T13:53:02.043348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous constatons que cette mesure est meilleure pour la varaible englobant Title et Body *(Full_doc)*.","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\" id=\"section_2\">Modèles non supervisés</span>\n\n## <span id=\"section_2_1\">Modèle LDA</span>\nLDA, ou **Latent Derelicht Analysis** est un modèle probabiliste qui, pour obtenir des affectations de cluster, utilise deux valeurs de probabilité : $P(word | topics)$ et $P(topics | documents)$. Ces valeurs sont calculées sur la base d'une attribution aléatoire initiale, puis le calcul est répété pour chaque mot dans chaque document, pour décider de leur attribution de sujet. Dans cette méthode itérative, ces probabilités sont calculées plusieurs fois, jusqu'à la convergence de l'algorithme.\n\nNous allons entrainer 1 seul modèle basé sur la variable `Full_doc` en utilisant la librairie spécialisée **Gensim**. Pour cette partie, nous n'utiliserons pas le preprocessing TFIDF mais des fonctions propres aux méthodes Gensim.\n\nDans une première étape, le Bag of words est créé ainsi que la matrice de fréquence des termes dans les documents :","metadata":{}},{"cell_type":"code","source":"# Create dictionnary (bag of words)\nid2word = corpora.Dictionary(X_train.Full_doc)\nid2word.filter_extremes(no_below=4, no_above=0.6, keep_n=None)\n# Create Corpus \ntexts = X_train.Full_doc  \n# Term Document Frequency \ncorpus = [id2word.doc2bow(text) for text in texts]  \n# View \nprint(corpus[:1])","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:53:02.046357Z","iopub.execute_input":"2021-06-28T13:53:02.046644Z","iopub.status.idle":"2021-06-28T13:53:06.541488Z","shell.execute_reply.started":"2021-06-28T13:53:02.046619Z","shell.execute_reply":"2021-06-28T13:53:06.540074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gensim crée un identifiant unique pour chaque mot du document puis mappe word_id et word_frequency. Exemple : (6,3) ci-dessus indique que word_id 6 apparaît 3 fois dans le document et ainsi de suite.      \nLes mots les plus fréquents ont ici aussi été filtrés grâce à la fonction `filter_extremes` réglée à 60% comme pour le Tfidf.\n\nPour voir quel mot correspond à un identifiant donné, il faut transmettre l'identifiant comme clé du dictionnaire. Exemple : id2word[4] :","metadata":{}},{"cell_type":"code","source":"[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:53:06.542786Z","iopub.execute_input":"2021-06-28T13:53:06.543156Z","iopub.status.idle":"2021-06-28T13:53:06.55413Z","shell.execute_reply.started":"2021-06-28T13:53:06.543121Z","shell.execute_reply":"2021-06-28T13:53:06.552806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous allons à présent entrainer le modèle LDA sur Full_doc puis afficher les métriques : \n- **Perplexity** : $(\\exp(-1 \\times \\text{log-likelihood})$ *(Log likelihood : Densité de vraisemblance)*\n- **Coherence Score** : Les mesures de cohérence de topics évaluent un seul topic en mesurant le degré de similitude sémantique entre les mots à score élevé dans ce dernier.       Pour en savoir plus sur ce Pipeline : [What is topic coherence ?](https://rare-technologies.com/what-is-topic-coherence/)","metadata":{}},{"cell_type":"code","source":"# Build LDA model\nfull_lda_model = gensim.models.ldamulticore\\\n                    .LdaMulticore(corpus=corpus,\n                                  id2word=id2word,\n                                  num_topics=20,\n                                  random_state=8,\n                                  per_word_topics=True,\n                                  workers=4)\n# Print Perplexity score\nprint('\\nPerplexity: ', full_lda_model.log_perplexity(corpus))\n\n#Print Coherence Score\ncoherence_model_lda = CoherenceModel(model=full_lda_model, \n                                     texts=texts, \n                                     dictionary=id2word, \n                                     coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:53:06.555543Z","iopub.execute_input":"2021-06-28T13:53:06.555777Z","iopub.status.idle":"2021-06-28T13:54:07.994209Z","shell.execute_reply.started":"2021-06-28T13:53:06.555752Z","shell.execute_reply":"2021-06-28T13:54:07.993082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:#641E16;\">Visualisation des résultats de LDA Gensim sur Full_doc avec 20 topics</span>","metadata":{}},{"cell_type":"code","source":"pyLDAvis.enable_notebook()\ngensimvis.prepare(full_lda_model, corpus, id2word)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:54:07.995898Z","iopub.execute_input":"2021-06-28T13:54:07.996186Z","iopub.status.idle":"2021-06-28T13:54:33.726625Z","shell.execute_reply.started":"2021-06-28T13:54:07.99616Z","shell.execute_reply":"2021-06-28T13:54:33.722433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"D'après les résulatas de cette modélisation LDA, il semble très **difficile de \"nommer\" les topics créés car les mots qui les composent sont très variés et sans fil conducteur clairement établi**. On voit cependant par exemple que le topic représenté par \"server\" englobe également \"database\", \"sql\", \"connection\" ou encore \"query\" ce qui est cohérent.\n\n### Amélioration du modèle LDA\n\nCependant, dans l'algoritmes LDA, nous avons fixé arbitrairement à 20 le paramètre `num_topics` qui représente le nombre de topics à créer. Afin de sélectionner le meilleur nombre de topics pour nos données, nous allons **itérer sur une fourchette de nombre de topics et tester le score de cohérence pour chaque modèle** :","metadata":{}},{"cell_type":"code","source":"# Iter LDA for best number of topics\ncoherence_test = []\nfor k in np.arange(1,90,10):\n    print(\"Fitting LDA for K = {}\".format(k))\n    start_time = time.time()\n    lda_model = gensim.models.ldamulticore\\\n                    .LdaMulticore(corpus=corpus,\n                                  id2word=id2word,\n                                  num_topics=k,\n                                  random_state=8,\n                                  per_word_topics=True,\n                                  workers=4)\n    coherence_model_lda = CoherenceModel(model=lda_model,\n                                         texts=texts,\n                                         dictionary=id2word,\n                                         coherence='c_v')\n    coherence_lda = coherence_model_lda.get_coherence()\n    end_time = time.time()\n    coherence_test.append((k, coherence_lda, (end_time - start_time)))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:54:33.727869Z","iopub.execute_input":"2021-06-28T13:54:33.728109Z","iopub.status.idle":"2021-06-28T13:59:31.213143Z","shell.execute_reply.started":"2021-06-28T13:54:33.72808Z","shell.execute_reply":"2021-06-28T13:59:31.21176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Affichons les scores des divers modèle :","metadata":{}},{"cell_type":"code","source":"# Create dataframe of results\ncoherence_test = pd.DataFrame(coherence_test,\n                              columns=[\"k\",\"coherence\",\"time\"])\n\n# Select best number of topics\nbest_nb_topics = coherence_test\\\n                    .loc[coherence_test.coherence.argmax(),\"k\"]\n\n# Plot results\nfig, ax1 = plt.subplots(figsize=(12,8))\nx = coherence_test[\"k\"]\ny1 = coherence_test[\"coherence\"]\ny2 = coherence_test[\"time\"]\n\nax1.plot(x, y1, label=\"Coherence score\")\nax1.axvline(x=best_nb_topics, color='r', alpha=.7,\n            linestyle='dashdot', label='Best param')\nax1.set_xlabel(\"Number of components\")\nax1.set_ylabel(\"Coherence score\")\n\nax2 = ax1.twinx()\nax2.plot(x, y2, label=\"Fit time\",\n         color='g', alpha=.5,\n         linestyle='--')\nax2.set_ylabel(\"Fitting time (s)\")\n\nplt.title(\"Choosing Optimal LDA Model\\n\",\n          color=\"#641E16\", fontsize=18)\nlegend = fig.legend(loc=1, bbox_to_anchor=(.92, .9))\n\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:59:31.214924Z","iopub.execute_input":"2021-06-28T13:59:31.215223Z","iopub.status.idle":"2021-06-28T13:59:31.628482Z","shell.execute_reply.started":"2021-06-28T13:59:31.215197Z","shell.execute_reply":"2021-06-28T13:59:31.62715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Testons à présent le modèle avec le meilleur nombre théorique de topics pour l'afficher avec LDAvis :","metadata":{}},{"cell_type":"code","source":"# Best LDA visualization\n# Construire le modèle LDA\nbest_lda_model = gensim.models.ldamulticore\\\n                    .LdaMulticore(corpus=corpus,\n                                  id2word=id2word,\n                                  num_topics=best_nb_topics,\n                                  random_state=8,\n                                  per_word_topics=True,\n                                  workers=4)\ngensimvis.prepare(best_lda_model, corpus, id2word)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T13:59:31.630046Z","iopub.execute_input":"2021-06-28T13:59:31.630372Z","iopub.status.idle":"2021-06-28T14:00:16.943518Z","shell.execute_reply.started":"2021-06-28T13:59:31.630337Z","shell.execute_reply":"2021-06-28T14:00:16.942343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pour attribuer des Tags à chaque question sur ces modèles non-supervisés, nous allons **créer une matrice Topic/Tags** en réalisant une multiplication matricielle des matrices Document / Topic et Document / Tags.","metadata":{}},{"cell_type":"code","source":"# Calculate Document/topic matrix with Gensim\ndoc_topic = pd.DataFrame(best_lda_model.get_document_topics(corpus, minimum_probability=0))\nfor topic in doc_topic.columns:\n    doc_topic[topic] = doc_topic[topic].apply(lambda x : x[1])\n\nprint('document/tag : ', y_binarized.shape)\nprint('document/topic : ', doc_topic.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:00:16.944778Z","iopub.execute_input":"2021-06-28T14:00:16.945019Z","iopub.status.idle":"2021-06-28T14:00:49.300155Z","shell.execute_reply.started":"2021-06-28T14:00:16.944992Z","shell.execute_reply":"2021-06-28T14:00:49.299366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print documents / topic matrix\ndoc_topic.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:00:49.301014Z","iopub.execute_input":"2021-06-28T14:00:49.30123Z","iopub.status.idle":"2021-06-28T14:00:49.324302Z","shell.execute_reply.started":"2021-06-28T14:00:49.301206Z","shell.execute_reply":"2021-06-28T14:00:49.322923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A présent, créons la matrice Topic / Tags grâce aux probabilités obtenues :","metadata":{}},{"cell_type":"code","source":"# Matricial multiplication with Document / Topics transpose\ntopic_tag = np.matmul(doc_topic.T, y_binarized)\ntopic_tag.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:00:49.3256Z","iopub.execute_input":"2021-06-28T14:00:49.325824Z","iopub.status.idle":"2021-06-28T14:00:49.36242Z","shell.execute_reply.started":"2021-06-28T14:00:49.3258Z","shell.execute_reply":"2021-06-28T14:00:49.361785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_tag","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:00:49.363561Z","iopub.execute_input":"2021-06-28T14:00:49.363824Z","iopub.status.idle":"2021-06-28T14:00:49.4121Z","shell.execute_reply.started":"2021-06-28T14:00:49.363795Z","shell.execute_reply":"2021-06-28T14:00:49.41148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous obtenons donc une matrice dont les lignes représentent les Topics créés et les colonnes les Tags associés et leurs distribution. Nous allons donc **créer nos prédictions en prenant les** $\\large n$ **premiers tags associés aux topics** de chaque document :","metadata":{}},{"cell_type":"code","source":"y_results = pd.DataFrame(y_train)\ny_results[\"best_topic\"] = doc_topic.idxmax(axis=1).values\ny_results[\"nb_tags\"] = y_results[\"Tags\"].apply(lambda x : len(x))\n\ndf_y_bin = pd.DataFrame(y_binarized)\ndf_dict = dict(\n    list(\n        df_y_bin.groupby(df_y_bin.index)\n    )\n)\n\ntags_num = []\nfor k, v in df_dict.items():\n    check = v.columns[(v == 1).any()]\n    tags_num.append(check.to_list())\n\ny_results[\"y_true\"] = tags_num\ny_results.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:00:49.413072Z","iopub.execute_input":"2021-06-28T14:00:49.413456Z","iopub.status.idle":"2021-06-28T14:01:35.847513Z","shell.execute_reply.started":"2021-06-28T14:00:49.413426Z","shell.execute_reply":"2021-06-28T14:01:35.845554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select predicted tags in Topics / Tags matrix\nlist_tag = []\nfor row in y_results.itertuples():\n    nb_tags = row.nb_tags\n    best_topic = row.best_topic\n    row_tags = list(topic_tag.iloc[best_topic].sort_values(ascending=False)[0:nb_tags].index)\n    list_tag.append(row_tags)\n    \ny_results[\"y_pred\"] = list_tag\ny_results.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous allons tester plusieurs métriques sur ce modèle LDA :\n- Accuracy score :\n- F1 score :\n- Jaccard similarity score : \n- Recall :\n- Precision :","metadata":{}},{"cell_type":"code","source":"def metrics_score(model, df, y_true, y_pred):\n    if(df is not None):\n        temp_df = df\n    else:\n        temp_df = pd.DataFrame(index=[\"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"],\n                               columns=[model])\n        \n    scores = []\n    scores.append(metrics.accuracy_score(y_true, y_pred))\n    scores.append(metrics.f1_score(y_pred, y_true, average='weighted'))\n    scores.append(metrics.jaccard_score(y_true, y_pred, average='weighted'))\n    scores.append(metrics.recall_score(y_true, y_pred, average='weighted'))\n    scores.append(metrics.precision_score(y_true, y_pred, average='weighted'))\n    temp_df[model] = scores\n    \n    return temp_df","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:02:45.033979Z","iopub.execute_input":"2021-06-28T14:02:45.034333Z","iopub.status.idle":"2021-06-28T14:02:45.041383Z","shell.execute_reply.started":"2021-06-28T14:02:45.034279Z","shell.execute_reply":"2021-06-28T14:02:45.039839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"metrics_score(\"LDA\", df=None, \n              y_true=y_results.y_true, \n              y_pred=y_results.y_pred)","metadata":{}},{"cell_type":"markdown","source":"On remarque ici que la modélisation non supervisée avec LDA n'est pas adaptée. En effet, le meilleur nombre de topics se situerait à 31, mais **l'algorithme ne parvient pas a établir de groupes bien distincts**. Un certain nombre de topics sont très regroupés et donc représentés par les mêmes termes.\n\nNous allons donc tester une seconde modélisation non supervisée.\n\n## <span id=\"section_2_2\">Modèle NMF</span>\n<details>\n  <summary style=\"color:blue;\">Explication du modèle</summary>\n  \n  ## NMF\n  La factorisation matricielle non négative *(**N**on-negative **M**atrix **F**actorization)* est un modèle linéaire-algéabrique, qui factorise des vecteurs de grande dimension dans une représentation de faible dimension. Similaire à l'analyse en composantes principales *(PCA)*, NMF profite du fait que **les vecteurs sont non négatifs**. En les factorisant dans la forme de dimension inférieure, NMF force les coefficients à être également non négatifs.<br/><br/>\n    Prenons une matrice d'origine $A$, nous pouvons obtenir deux matrices $W$ et $H$, telles que $A = WH$. NMF a une propriété de clustering, telle que $W$ et $H$ représentent les informations suivantes sur $A$ :\n    <ul><li>$A$ (Matrice Document-word) : Matrice qui contient \"quels mots apparaissent dans quels documents\".</li>\n    <li>$W$ (Vecteurs de base) : Topics découverts à partir des documents.</li>\n    <li>$H$ (Matrice de coefficients) : les poids pour les topics dans chaque document.</li></ul><br/>\n    Nous calculons $W$ et $H$ en optimisant sur une **fonction objectif**, en mettant à jour à la fois $W$ et $H$ de manière itérative jusqu'à convergence.</br></br>\n    $$\\large \\frac{1}{2} ||A - WH||^2_F = \\sum_{i=1}^{n} \\sum_{j=1}^{m} (A_{ij} - (WH)_{ij})^2$$</br>\n    Dans cette fonction objectif, nous mesurons l'erreur de reconstruction entre A et le produit de ses facteurs W et H, en fonction de la distance euclidienne. Les valeurs mises à jour sont calculées dans des opérations parallèles, et en utilisant les nouveaux W et H, nous recalculons l'erreur de reconstruction, en répétant ce processus jusqu'à la convergence.\n</details>","metadata":{}},{"cell_type":"markdown","source":"Le modèle **NMF ne peut malheureusement pas être scoré**. Nous allons donc nous baser sur les résultats de la LDA pour déterminer un nombre correct de composants. Ici, nous prendrons **12 topics** pour avoir un bon compromis \"temps d'entrainement\" / précision et utiliserons les matrices Tfidf créées lors du preprocessing.","metadata":{}},{"cell_type":"code","source":"# Define number of topics to test\nn_topics = best_nb_topics\n\nprint(\"-\"*50)\nprint(\"Start NMF fitting on Title ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\ntitle_nmf = NMF(n_components=n_topics,\n                init='nndsvd',\n                random_state=8)\n\n# Fit NMF on Title vectorized\ntitle_nmf.fit(Xt_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:01:35.849043Z","iopub.execute_input":"2021-06-28T14:01:35.849401Z","iopub.status.idle":"2021-06-28T14:01:38.631118Z","shell.execute_reply.started":"2021-06-28T14:01:35.849366Z","shell.execute_reply":"2021-06-28T14:01:38.630499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'entrainement est plus rapide que pour LDA. Visualisons à présent les résulats en plotant **les 20 meilleurs mots de chaque topic**.","metadata":{}},{"cell_type":"code","source":"def plot_top_words(model, feature_names, n_top_words, nb_topic_plot, title):\n    \"\"\"Function for displaying the plots of the \n    best x words representative of the categories of NMF.\n\n    Parameters\n    ----------------------------------------\n    model : NMF model\n        Fitted model of NMF to plot\n    feature_names : array\n        Categories result of the vectorizer (TFIDF ...)\n    n_top_words : int\n        Number of words for each topic.\n    title : string\n        Title of the plot.\n    ----------------------------------------\n    \"\"\"\n    rows = int(nb_topic_plot/6)\n    fig, axes = plt.subplots(rows, 6, \n                             figsize=(30, rows*10), \n                             sharex=True)\n    axes = axes.flatten()\n    for topic_idx, topic in enumerate(model.components_):\n        if(topic_idx < nb_topic_plot):\n            top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n            top_features = [feature_names[i] for i in top_features_ind]\n            weights = topic[top_features_ind]\n\n            ax = axes[topic_idx]\n            bartopic = ax.barh(top_features, weights, height=0.7)\n            bartopic[0].set_color('#f48023')\n            ax.set_title(f'Topic {topic_idx +1}',\n                         fontdict={'fontsize': 30})\n            ax.invert_yaxis()\n            ax.tick_params(axis='both', which='major', labelsize=20)\n            for i in 'top right left'.split():\n                ax.spines[i].set_visible(False)\n            fig.suptitle(title, fontsize=36, color=\"#641E16\")\n\n    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:01:38.632089Z","iopub.execute_input":"2021-06-28T14:01:38.632459Z","iopub.status.idle":"2021-06-28T14:01:38.641073Z","shell.execute_reply.started":"2021-06-28T14:01:38.63243Z","shell.execute_reply":"2021-06-28T14:01:38.640363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the 12 first topics\ntf_feature_names = title_vectorizer.get_feature_names()\nplot_top_words(title_nmf, tf_feature_names, 20, 12,\n               'Topics in NMF model for Title feature')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:01:38.643902Z","iopub.execute_input":"2021-06-28T14:01:38.644386Z","iopub.status.idle":"2021-06-28T14:01:41.040149Z","shell.execute_reply.started":"2021-06-28T14:01:38.644355Z","shell.execute_reply":"2021-06-28T14:01:41.039198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**La modélisation avec NMF nous apporte des catégories plus lisibles que celles de l'algorithme LDA**. 1 mot est toujours beaucoup plus représentaif de cette catégorie mais les regroupements sont globalement cohérents. Un topic par exemple illustre bien les sujets liés à Python. un second traite les sujets liés à Android ...\n\nNous allons **tester cette modélisation sur la variable Body** cette fois :","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start NMF fitting on Body ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\nbody_nmf = NMF(n_components=n_topics,\n               init='nndsvd',\n               random_state=8)\n\n# Fit NMF on Body vectorized\nbody_nmf.fit(Xb_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)\n\nbf_feature_names = body_vectorizer.get_feature_names()\nplot_top_words(body_nmf, bf_feature_names, 20, 12,\n               'Topics in NMF model for Body feature')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:01:41.0414Z","iopub.execute_input":"2021-06-28T14:01:41.041643Z","iopub.status.idle":"2021-06-28T14:02:06.636957Z","shell.execute_reply.started":"2021-06-28T14:01:41.041611Z","shell.execute_reply":"2021-06-28T14:02:06.635429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Basé sur le corpus Body, le modèle fait sortir des thèmes différents, plus génériques. **NMF est également beaucoup plus rapide que LDA**, ce qui est un atout pour en terme de puissance de calcul nécessaire.","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Start NMF fitting on Full_doc ...\")\nprint(\"-\" * 50)\nstart_time = time.time()\n# Initializing the NMF\nfull_nmf = NMF(n_components=n_topics,\n               init='nndsvd',\n               random_state=8)\n\n# Fit NMF on Body vectorized\nfull_nmf.fit(X_tfidf)\n\nexec_time = time.time() - start_time\nprint(\"End of training :\")\nprint(\"Execution time : {:.2f}s\".format(exec_time))\nprint(\"-\" * 50)\n\nff_feature_names = full_vectorizer.get_feature_names()\nplot_top_words(full_nmf, ff_feature_names, 20, 12,\n               'Topics in NMF model for Full_doc')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:02:06.63865Z","iopub.execute_input":"2021-06-28T14:02:06.638931Z","iopub.status.idle":"2021-06-28T14:02:24.759903Z","shell.execute_reply.started":"2021-06-28T14:02:06.638902Z","shell.execute_reply":"2021-06-28T14:02:24.759083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La modélisation NMF sur la variable `Full_doc` semble offrir de meilleurs résultats dans la contribution des termes aux topics. Nous conserverons donc cette variable pour la suite des analyses. ","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:#641E16\" id=\"section_3\">Modèles supervisés</span>\n\n## <span id=\"section_3_1\">Régression logistique avec multi-labels</span>\nNous avons déjà réalisé quelques Notebook traitant de la régression logistique : c'est une technique prédictive. Elle vise à construire un modèle permettant de prédire / expliquer les valeurs prises par une variable cible qualitative à partir d’un ensemble de variables explicatives quantitatives ou qualitatives encodées.\n\nPour cette partie sur les modélisations supervisées, nous allons utiliser la variable `Full_doc` qui regroupe le Title et le Body puis créer un Pipeline qui ne pourra pas inclure la transformation de notre variable cible *(MultiLabelBinarizer ne fonctionne pas dans les Pipeline SKlearn)*.","metadata":{}},{"cell_type":"code","source":"# Fixe X to Full_doc\nX_train = X_train['Full_doc']\nX_test = X_test['Full_doc']\n\n# create pipeline with preprocessing\nmlb = MultiLabelBinarizer()\ny_train_mlb = mlb.fit_transform(y_train)\ny_test_mlb = mlb.fit_transform(y_test)\nmulti_logit = Pipeline([(\"vectorizer\", TfidfVectorizer(analyzer=\"word\",\n                                                       max_df=.6,\n                                                       min_df=0.005,\n                                                       tokenizer=None,\n                                                       preprocessor=' '.join,\n                                                       stop_words=None,\n                                                       lowercase=False)),\n                        (\"logit\", OneVsRestClassifier(LogisticRegression(C=1.0, \n                                                                         penalty='l1', \n                                                                         dual=False, \n                                                                         solver='liblinear')))])\nmulti_logit.fit(X_train, y_train_mlb)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:02:24.760852Z","iopub.execute_input":"2021-06-28T14:02:24.761216Z","iopub.status.idle":"2021-06-28T14:02:44.287424Z","shell.execute_reply.started":"2021-06-28T14:02:24.761175Z","shell.execute_reply":"2021-06-28T14:02:44.286908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nous pouvons maintenant **réaliser les prédictions avec le modèle de régression logistique sur le jeu de test** pour pouvoir les comparer avec le jeu y_test.","metadata":{}},{"cell_type":"code","source":"# Predict\ny_test_predicted_labels_tfidf = multi_logit.predict(X_test)\n\n# Inverse transform\ny_test_pred_inversed = mlb.inverse_transform(y_test_predicted_labels_tfidf)\ny_test_inversed = mlb.inverse_transform(y_test_mlb)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:02:44.28828Z","iopub.execute_input":"2021-06-28T14:02:44.288625Z","iopub.status.idle":"2021-06-28T14:02:45.033037Z","shell.execute_reply.started":"2021-06-28T14:02:44.288591Z","shell.execute_reply":"2021-06-28T14:02:45.032428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_metrics_compare = metrics_score(\"Logit\", df=None, \n              y_true = y_test_mlb, \n              y_pred = y_test_predicted_labels_tfidf)\ndf_metrics_compare","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:02:45.042645Z","iopub.execute_input":"2021-06-28T14:02:45.042884Z","iopub.status.idle":"2021-06-28T14:02:45.554205Z","shell.execute_reply.started":"2021-06-28T14:02:45.04286Z","shell.execute_reply":"2021-06-28T14:02:45.553197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span id=\"section_3_2\">Modélisation avec RandomForest</span>","metadata":{}},{"cell_type":"code","source":"# create pipeline with preprocessing\nmulti_rfc = Pipeline([(\"vectorizer\", TfidfVectorizer(analyzer=\"word\",\n                                                       max_df=.6,\n                                                       min_df=0.005,\n                                                       tokenizer=None,\n                                                       preprocessor=' '.join,\n                                                       stop_words=None,\n                                                       lowercase=False)),\n                        (\"randomForest\", OneVsRestClassifier(RandomForestClassifier(n_jobs=-1)))])\nmulti_rfc.fit(X_train, y_train_mlb)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:02:45.55535Z","iopub.execute_input":"2021-06-28T14:02:45.555563Z","iopub.status.idle":"2021-06-28T14:12:26.63014Z","shell.execute_reply.started":"2021-06-28T14:02:45.55554Z","shell.execute_reply":"2021-06-28T14:12:26.628648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict\ny_test_predicted_labels_tfidf_rfc = multi_rfc.predict(X_test)\n\ndf_metrics_compare = metrics_score(\"RandomForest\", df=df_metrics_compare, \n              y_true = y_test_mlb, \n              y_pred = y_test_predicted_labels_tfidf_rfc)\ndf_metrics_compare","metadata":{"execution":{"iopub.status.busy":"2021-06-28T14:12:26.631494Z","iopub.execute_input":"2021-06-28T14:12:26.631784Z","iopub.status.idle":"2021-06-28T14:12:41.985847Z","shell.execute_reply.started":"2021-06-28T14:12:26.631755Z","shell.execute_reply":"2021-06-28T14:12:41.985019Z"},"trusted":true},"execution_count":null,"outputs":[]}]}